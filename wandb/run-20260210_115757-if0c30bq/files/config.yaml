_wandb:
    value:
        cli_version: 0.24.2
        e:
            khdtie45fd806nhqr8h5wg4cgv4vp62a:
                args:
                    - --ckpt
                    - skysense_model_backbone_hr.pth
                    - --epochs
                    - "1"
                    - --batch_size
                    - "32"
                    - --train_split
                    - "0.1"
                    - --save_path
                    - jobs/checkpoints/sanity_model.pth
                    - --wandb_project
                    - LoRA_resisc45_sanity
                codePath: train_resisc45_lora.py
                codePathLocal: train_resisc45_lora.py
                cpu_count: 52
                cpu_count_logical: 52
                cudaVersion: "12.6"
                disk:
                    /:
                        total: "337378443264"
                        used: "28008779776"
                email: winnerabula55@gmail.com
                executable: /apps/ku/miniconda/3/bin/python
                git:
                    commit: 577f9f112f4c171d619487502322289957509a6f
                    remote: git@github.com:Eyobed-Abby/Skysense_FoundationModel_Finetuning.git
                gpu: Tesla V100-PCIE-32GB
                gpu_count: 4
                gpu_nvidia:
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "34359738368"
                      name: Tesla V100-PCIE-32GB
                      uuid: GPU-b2f4fa61-ea71-5e39-c472-c210c905564a
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "34359738368"
                      name: Tesla V100-PCIE-32GB
                      uuid: GPU-01fec9fd-d6fc-f99f-c350-adc9162a9b95
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "34359738368"
                      name: Tesla V100-PCIE-32GB
                      uuid: GPU-6a1f1c66-766b-324f-b872-4878aef9e36e
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "34359738368"
                      name: Tesla V100-PCIE-32GB
                      uuid: GPU-62344959-635a-2915-9d58-13b5d86858a7
                host: gpu-11-3
                memory:
                    total: "674756890624"
                os: Linux-4.18.0-372.9.1.el8.x86_64-x86_64-with-glibc2.28
                program: /dpc/kuin0137/LoRA_Experiment/classification/Updated_Vanilla/Skysense_FoundationModel_Finetuning/train_resisc45_lora.py
                python: CPython 3.9.18
                root: /dpc/kuin0137/LoRA_Experiment/classification/Updated_Vanilla/Skysense_FoundationModel_Finetuning
                slurm:
                    cluster_name: almesbar
                    conf: /global/opt/apps/slurm/21.08.8.2/etc/slurm.conf
                    cpu_bind: quiet,mask_cpu:0x00003C0000000
                    cpu_bind_list: "0x00003C0000000"
                    cpu_bind_type: 'mask_cpu:'
                    cpu_bind_verbose: quiet
                    cpus_on_node: "4"
                    cpus_per_task: "4"
                    distribution: cyclic
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: kuin0137
                    job_cpus_per_node: "4"
                    job_cpus_per_node_pack_group_0: "4"
                    job_gid: "10000"
                    job_gpus: "2"
                    job_id: "3989100"
                    job_name: resisc45_lora_sanity
                    job_nodelist: gpu-11-3
                    job_num_nodes: "1"
                    job_partition: gpu
                    job_qos: normal
                    job_uid: "70539"
                    job_user: 100066896@kunet.ae
                    jobid: "3989100"
                    launch_node_ipaddr: 10.126.11.3
                    localid: "0"
                    mem_per_node: "32768"
                    mpi_type: pmix
                    nnodes: "1"
                    node_aliases: (null)
                    nodeid: "0"
                    nodelist: gpu-11-3
                    nprocs: "1"
                    ntasks: "1"
                    pmix_mapping_serv: (vector,(0,1,1))
                    pmixp_abort_agent_port: "42059"
                    prio_process: "0"
                    procid: "0"
                    srun_comm_host: 10.126.11.3
                    srun_comm_port: "41215"
                    step_gpus: "2"
                    step_id: "0"
                    step_launcher_port: "41215"
                    step_nodelist: gpu-11-3
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /dpc/kuin0137/LoRA_Experiment/classification/Updated_Vanilla/Skysense_FoundationModel_Finetuning
                    submit_host: login-2
                    task_pid: "19144"
                    tasks_per_node: "1"
                    topology_addr: gpu-11-3
                    topology_addr_pattern: node
                    umask: "0022"
                    working_cluster: almesbar:10.126.2.252:6817:9472:101
                startedAt: "2026-02-10T07:57:57.742273Z"
                writerId: khdtie45fd806nhqr8h5wg4cgv4vp62a
        m: []
        python_version: 3.9.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 37
                - 41
                - 49
                - 51
                - 53
                - 62
                - 63
                - 71
                - 98
            "2":
                - 1
                - 5
                - 11
                - 37
                - 41
                - 49
                - 51
                - 53
                - 62
                - 63
                - 71
                - 98
            "3":
                - 16
            "4": 3.9.18
            "5": 0.24.2
            "6": 4.57.1
            "12": 0.24.2
            "13": linux-x86_64
batch_size:
    value: 32
ckpt:
    value: skysense_model_backbone_hr.pth
epochs:
    value: 1
lr:
    value: 6.25e-05
save_path:
    value: jobs/checkpoints/sanity_model.pth
train_split:
    value: 0.1
wandb_project:
    value: LoRA_resisc45_sanity
